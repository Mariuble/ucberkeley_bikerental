{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d77ab7e-b68d-4249-a5d1-de568cb9a4e7",
   "metadata": {},
   "source": [
    "In this notebook, we will use classification algorithms to predict the number of rented bikes for a given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd9c82a-71ac-4059-9e61-6184a53fb5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-01 17:20:54.862142: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import tensorflow as ts\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "seed=99\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3adce5-69cb-4843-975d-3ce9718fa78c",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2262965-d6b1-4688-94f5-849525b47960",
   "metadata": {},
   "source": [
    "Loading data from data_cleaning notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98423efd-6a92-4e60-8796-ae1e1af30319",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental = pd.read_csv('../data/rental.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d67084a-cab2-4d0d-8c88-9d24463228cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>weekday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>season_4</th>\n",
       "      <th>holiday_0</th>\n",
       "      <th>holiday_1</th>\n",
       "      <th>workingday_0</th>\n",
       "      <th>workingday_1</th>\n",
       "      <th>weathersit_1</th>\n",
       "      <th>weathersit_2</th>\n",
       "      <th>weathersit_3</th>\n",
       "      <th>weathersit_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mnth  hr  weekday  temp   atemp   hum  windspeed  cnt  season_1  season_2  \\\n",
       "0     1   0        6  0.24  0.2879  0.81        0.0   16       1.0       0.0   \n",
       "1     1   1        6  0.22  0.2727  0.80        0.0   40       1.0       0.0   \n",
       "2     1   2        6  0.22  0.2727  0.80        0.0   32       1.0       0.0   \n",
       "3     1   3        6  0.24  0.2879  0.75        0.0   13       1.0       0.0   \n",
       "4     1   4        6  0.24  0.2879  0.75        0.0    1       1.0       0.0   \n",
       "\n",
       "   season_3  season_4  holiday_0  holiday_1  workingday_0  workingday_1  \\\n",
       "0       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "1       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "2       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "3       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "4       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "\n",
       "   weathersit_1  weathersit_2  weathersit_3  weathersit_4  \n",
       "0           1.0           0.0           0.0           0.0  \n",
       "1           1.0           0.0           0.0           0.0  \n",
       "2           1.0           0.0           0.0           0.0  \n",
       "3           1.0           0.0           0.0           0.0  \n",
       "4           1.0           0.0           0.0           0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rental.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801faaef-0a3e-4dba-bab7-dce188ca69a7",
   "metadata": {},
   "source": [
    "Checking the distribution of the number of bikes rented each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2465eaf2-1df3-4e5c-bc5e-bbf32e8ef5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = rental['cnt'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8420beea-ff52-43c3-86fd-811d833bb5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of \"cnt\" feature 142.0000\n"
     ]
    }
   ],
   "source": [
    "median = rental['cnt'].median()\n",
    "\n",
    "print(f'Median of \"cnt\" feature {median:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7d5fa7-5f60-4660-9fc1-8436144409ba",
   "metadata": {},
   "source": [
    "We want to create two new dataframes to use in the classification models. One for two-class classification and one for multi-class classification. The median of the \"cnt\" feature was 142. For the dataframe that we will use for two-class classification, this feature will be replaced with a feature with the value 1 if 142 or more bikes were rented that given hour and 0 if fewer than 142 bikes were rented that given hour. \n",
    "\n",
    "Most instances are between 0 and 200, which means that it was mostly a number of bikes between 0 and 200 that was rented for a given hour. Few instances were over 600, which means that rarely over 600 bikes were rented for a given hour. Therefore, we found it sufficient to classify the \"cnt\" feature into six diffrent categories for the dataframe we will use for the multi-class classification problems. We chose three splits for the range between 0 and 200 bikes, which was <50, 50-100 and 100-200, because most instances were found in this interval. The remaining categories are 200-400, 400-600 and >600."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b1d4a9-7a5c-4ca6-8f7a-0ac3ae990168",
   "metadata": {},
   "source": [
    "#### Two-class classification dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986d017d-038c-48c4-9d8a-135dd001b218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>weekday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>season_4</th>\n",
       "      <th>holiday_0</th>\n",
       "      <th>holiday_1</th>\n",
       "      <th>workingday_0</th>\n",
       "      <th>workingday_1</th>\n",
       "      <th>weathersit_1</th>\n",
       "      <th>weathersit_2</th>\n",
       "      <th>weathersit_3</th>\n",
       "      <th>weathersit_4</th>\n",
       "      <th>&gt;=142</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mnth  hr  weekday  temp   atemp   hum  windspeed  season_1  season_2  \\\n",
       "0     1   0        6  0.24  0.2879  0.81        0.0       1.0       0.0   \n",
       "1     1   1        6  0.22  0.2727  0.80        0.0       1.0       0.0   \n",
       "2     1   2        6  0.22  0.2727  0.80        0.0       1.0       0.0   \n",
       "3     1   3        6  0.24  0.2879  0.75        0.0       1.0       0.0   \n",
       "4     1   4        6  0.24  0.2879  0.75        0.0       1.0       0.0   \n",
       "\n",
       "   season_3  season_4  holiday_0  holiday_1  workingday_0  workingday_1  \\\n",
       "0       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "1       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "2       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "3       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "4       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "\n",
       "   weathersit_1  weathersit_2  weathersit_3  weathersit_4  >=142  \n",
       "0           1.0           0.0           0.0           0.0      0  \n",
       "1           1.0           0.0           0.0           0.0      0  \n",
       "2           1.0           0.0           0.0           0.0      0  \n",
       "3           1.0           0.0           0.0           0.0      0  \n",
       "4           1.0           0.0           0.0           0.0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_class_df = rental.copy()\n",
    "\n",
    "two_class_df['>=142'] = np.where(two_class_df['cnt']>=median, 1, 0)\n",
    "two_class_df = two_class_df.drop(columns=['cnt'])\n",
    "\n",
    "two_class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ba3bc-9cee-453f-8521-f535e7b31f67",
   "metadata": {},
   "source": [
    "#### Multi-class classification dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c5632c-7a6e-4a8f-a987-872f0d6bfa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>weekday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>season_4</th>\n",
       "      <th>holiday_0</th>\n",
       "      <th>holiday_1</th>\n",
       "      <th>workingday_0</th>\n",
       "      <th>workingday_1</th>\n",
       "      <th>weathersit_1</th>\n",
       "      <th>weathersit_2</th>\n",
       "      <th>weathersit_3</th>\n",
       "      <th>weathersit_4</th>\n",
       "      <th>cnt_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mnth  hr  weekday  temp   atemp   hum  windspeed  season_1  season_2  \\\n",
       "0     1   0        6  0.24  0.2879  0.81        0.0       1.0       0.0   \n",
       "1     1   1        6  0.22  0.2727  0.80        0.0       1.0       0.0   \n",
       "2     1   2        6  0.22  0.2727  0.80        0.0       1.0       0.0   \n",
       "3     1   3        6  0.24  0.2879  0.75        0.0       1.0       0.0   \n",
       "4     1   4        6  0.24  0.2879  0.75        0.0       1.0       0.0   \n",
       "\n",
       "   season_3  season_4  holiday_0  holiday_1  workingday_0  workingday_1  \\\n",
       "0       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "1       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "2       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "3       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "4       0.0       0.0        1.0        0.0           1.0           0.0   \n",
       "\n",
       "   weathersit_1  weathersit_2  weathersit_3  weathersit_4 cnt_bins  \n",
       "0           1.0           0.0           0.0           0.0      <50  \n",
       "1           1.0           0.0           0.0           0.0      <50  \n",
       "2           1.0           0.0           0.0           0.0      <50  \n",
       "3           1.0           0.0           0.0           0.0      <50  \n",
       "4           1.0           0.0           0.0           0.0      <50  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class_df = rental.copy()\n",
    "\n",
    "labels = ['<50', '[50-100)', '[100-200)', '[200-400)', '[400-600)', '>600']\n",
    "bins = [0,50,100,200,400,600, float('inf')]\n",
    "\n",
    "multi_class_df['cnt_bins'] = pd.cut(multi_class_df['cnt'],bins=bins,labels=labels)\n",
    "\n",
    "multi_class_df = multi_class_df.drop(columns=['cnt'])\n",
    "\n",
    "multi_class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb216d6-1960-4a2e-aaf6-25e2402c1f4f",
   "metadata": {},
   "source": [
    "The \"cnt\" feature is modified to fit different classification models. The two new dataframes, two_class_df and multi_class_df, will be used for classification under \"Predictive modelling\" to find out which model performes best for classifying the number of bikes rented based on data about the given day and weather conditions. We will start with multi-class classification to get the most accurate prediction. However, if the model does not perform significantly better than the baseline model and the previous models, we will use two-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772db05f-20d7-42fb-99cf-478a3faece5c",
   "metadata": {},
   "source": [
    "# Predictive modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70551b6a-2ecc-4a0e-bf41-5a5ef5ac5f03",
   "metadata": {},
   "source": [
    "Creating two sets for 80% train data and 20% test data. One from the two_class_df dataframe with the feature \">=142\" as target variable, and one for the multi_class_df with the feature \"cnt_bins\" as the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c153a-a578-40f4-a4a3-bac6ca68d524",
   "metadata": {},
   "source": [
    "#### Train and test data for two-class classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f11a4f-0d07-4e29-b9a4-a5867082f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = two_class_df.loc[:, two_class_df.columns != '>=142']\n",
    "y = two_class_df['>=142']\n",
    "\n",
    "X_train_two, X_test_two, y_train_two, y_test_two = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157463d-1d9d-4d35-abb2-fc3279dcff3a",
   "metadata": {},
   "source": [
    "#### Train and test data for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367622be-fd9e-4ee3-baa6-d66d020ab0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = multi_class_df.loc[:, multi_class_df.columns != 'cnt_bins']\n",
    "y = multi_class_df['cnt_bins']\n",
    "\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff877e1-12ab-418c-8b37-561b833622e3",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b4a30-75ef-48f9-aae7-7cdb81dd02ab",
   "metadata": {},
   "source": [
    "We create two baseline models. One for multi-class classification and one for two-class classification. Both baseline models are DummyClassifiers that ignores the input features passed in as X and always predicts the most frequent class label in the y argument that is passed into fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8eb9c2-77fc-4fe0-b939-f7a5ce5211ab",
   "metadata": {},
   "source": [
    "#### Baseline model for two-class classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e156f4a-298c-4243-9837-d405ff12cc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data 0.5031\n",
      "Predictive score on test data 0.4931\n"
     ]
    }
   ],
   "source": [
    "baseline = DummyClassifier(strategy='most_frequent', random_state=seed).fit(X_train_two, y_train_two)\n",
    "\n",
    "train_score = baseline.score(X_train_two, y_train_two)\n",
    "print(f'Predictive score on training data {train_score:.4f}')\n",
    "\n",
    "test_score = baseline.score(X_test_two, y_test_two)\n",
    "print(f'Predictive score on test data {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441eef9-4a1e-4148-ac77-58dd02ddf485",
   "metadata": {},
   "source": [
    "#### Baseline model for multi-class classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6fca2a4-53f9-4feb-9128-4bd5946b5ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data 0.2792\n",
      "Predictive score on test data 0.2860\n"
     ]
    }
   ],
   "source": [
    "baseline = DummyClassifier(strategy='most_frequent', random_state=seed).fit(X_train_multi, y_train_multi)\n",
    "\n",
    "train_score = baseline.score(X_train_multi, y_train_multi)\n",
    "print(f'Predictive score on training data {train_score:.4f}')\n",
    "\n",
    "test_score = baseline.score(X_test_multi, y_test_multi)\n",
    "print(f'Predictive score on test data {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ebdd4-d381-4833-801c-b1335dad48a1",
   "metadata": {},
   "source": [
    "The accuracy of the two-class baseline model performes better than the multi-class baseline model. We expect the models to perform better with two-class classification, because it only has to assign the label to one of two classes. However, the multi-class classification will classify the output into more accurate bins. Therefore, we need to do a tradeoff between accuracy score and whether the classification is two-class or multi-class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78271a3-10bc-48ff-b344-c69119d05944",
   "metadata": {},
   "source": [
    "## Method 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24c6f04-1132-4fe3-92e4-db201735db98",
   "metadata": {},
   "source": [
    "The first classification model we want to try is logistic regression. Logistic regression is used for two-class problems, and will map the class label to 1 if the number of bikes rented are 142 or more for the given hour and 0 if it's less than 142. Therefore, we will use the two_class_df dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1164a8af-7262-4f85-a76e-89a2e1a95395",
   "metadata": {},
   "source": [
    "#### Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6520257b-03bc-4504-b2ba-6329ccebd36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data 0.7891\n",
      "Predictive score on test data 0.7926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=seed).fit(X_train_two, y_train_two)\n",
    "\n",
    "train_score = clf.score(X_train_two, y_train_two)\n",
    "print(f'Predictive score on training data {train_score:.4f}')\n",
    "\n",
    "test_score = clf.score(X_test_two, y_test_two)\n",
    "print(f'Predictive score on test data {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe49d9-6214-4f8a-9ae3-ea561b57e072",
   "metadata": {},
   "source": [
    "We change the penalty to L1 norm, because our dataset consists of many features. We will also tune the C hyperparameter which specifies the strength of the regularization to see if we can improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24c3f3d-fefe-4f54-92e8-3f4dec5cf7a6",
   "metadata": {},
   "source": [
    "#### Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84bb4bd7-4d8e-4548-8b4a-08c2c445e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data after modifications 0.7890\n",
      "Predictive score on test data after modifications 0.7923\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=seed, penalty='l1', solver='liblinear')\n",
    "\n",
    "param_grid = {'C':[0.5,1,1.5,2,2.5,3]}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, return_train_score=True).fit(X_train_two, y_train_two)\n",
    "\n",
    "train_score = grid_search.best_estimator_.fit(X_train_two,y_train_two).score(X_train_two, y_train_two)\n",
    "print(f'Predictive score on training data after modifications {train_score:.4f}')\n",
    "\n",
    "test_score = grid_search.best_estimator_.score(X_test_two, y_test_two)\n",
    "print(f'Predictive score on test data after modifications {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e8766-afe7-4104-9605-1f3a4ac57ff6",
   "metadata": {},
   "source": [
    "Changing the regularization technique to L1 norm and tuning the C parameter did not improve our model. However, the model performes significantly better on both the train data and test data compared to the baseline model for two-class classification. For about 79% of the test instances (hours), our model predicted correctly whether over or under 142 bikes were rented that given hour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa33ea-d6c5-4199-99c1-82c5b240d9b2",
   "metadata": {},
   "source": [
    "## Method 2: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ab009-a0f8-47ab-ad1d-7314e00c219c",
   "metadata": {},
   "source": [
    "The next classification method we will use is K-Nearest Neighbors, which will label the instance based on the label that is most frequently found around the data point. If the majority of the k nearest neighbors of a data point is have 100-200 rented bikes for a given hours, the label for this data point will be 100-200. We will start by doing multi-class classification to try and get a more exact prediction of the number of rented bikes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3bc2dc-93da-4da0-983d-f6c5676fd2b6",
   "metadata": {},
   "source": [
    "#### Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0aa922a-d614-49a7-a329-61a8b17fccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data 0.7550\n",
      "Predictive score on test data 0.6191\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier().fit(X_train_multi, y_train_multi)\n",
    "\n",
    "train_score = clf.score(X_train_multi, y_train_multi)\n",
    "print(f'Predictive score on training data {train_score:.4f}')\n",
    "\n",
    "test_score = clf.score(X_test_multi, y_test_multi)\n",
    "print(f'Predictive score on test data {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57159f6b-d4b7-473e-a8ba-3d6a8d319302",
   "metadata": {},
   "source": [
    "The train and test score is significantly better compared to the baseline model for multi-class classification. The model performes better on the train data than the test data. Therefore, we will tune the number of neighbors to consider as well as \"p\", which is either manhattan distance or eucledian distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59bf419-aaea-40e7-87aa-180f0c290639",
   "metadata": {},
   "source": [
    "#### Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc5082fd-f049-41b9-bf0b-e046a55da931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data after modifications 0.7304\n",
      "Predictive score on test data after modifications 0.6430\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors':range(1,10), 'p':[1,2]}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, return_train_score=True).fit(X_train_multi, y_train_multi)\n",
    "\n",
    "train_score = grid_search.best_estimator_.fit(X_train_multi, y_train_multi).score(X_train_multi, y_train_multi)\n",
    "print(f'Predictive score on training data after modifications {train_score:.4f}')\n",
    "\n",
    "test_score = grid_search.best_estimator_.score(X_test_multi, y_test_multi)\n",
    "print(f'Predictive score on test data after modifications {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e00ee8-8de4-4ee6-a8bb-f4479e0dd210",
   "metadata": {},
   "source": [
    "The results show that the test accuracy is slightly improved after tuning the parameters. \n",
    "\n",
    "Even though 64% test accuracy is significantly better than the 28% from the multi-class baseline model, we try to use the k-nearest neighbor algorithm with two-class classification to compare with the two-class baseline model and logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eca13781-477d-4f45-911e-eb0eddbd65e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data after modifications 0.9161\n",
      "Predictive score on test data after modifications 0.8979\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors':range(1,10), 'p':[1,2]}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, return_train_score=True).fit(X_train_two, y_train_two)\n",
    "\n",
    "train_score = grid_search.best_estimator_.fit(X_train_two, y_train_two).score(X_train_two, y_train_two)\n",
    "print(f'Predictive score on training data after modifications {train_score:.4f}')\n",
    "\n",
    "test_score = grid_search.best_estimator_.score(X_test_two, y_test_two)\n",
    "print(f'Predictive score on test data after modifications {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f777e45-93f0-447f-8202-98ab3444d7e1",
   "metadata": {},
   "source": [
    "The accuracy for two-class classification (test: 89%) is significantly better than the accuracy for multi-class classification (test: 64%). This makes sense because it's only two different categories to choose from in the classification vs six categories when we used the multi_class_df dataframe. \n",
    "\n",
    "Two-class k-nearest neighbors classification also performed better than logistic regression (test: 79%) and the two-class baseline model (test: 49%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18808f7-5659-4b66-a3d7-2abd3059fb14",
   "metadata": {},
   "source": [
    "## Method 3: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb5beb-3b5a-4a94-8e51-9d701db4762f",
   "metadata": {},
   "source": [
    "The third method we want to try out is desicion trees, which has nodes that performes tests on the features and each branch from the node repsesents the outcomes of the test. Again, we will start by using multi-class classification to try to get the most exact prediction, and check for two-class classification the first model doesn't perform significantly better than the baseline model and K-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ea647-9be5-49bd-a5c9-930a44bf3c7e",
   "metadata": {},
   "source": [
    "#### Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0db0c262-16cf-43b9-a225-e05b128e6ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data 0.9996\n",
      "Predictive score on test data 0.6418\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=seed).fit(X_train_multi, y_train_multi)\n",
    "\n",
    "train_score = clf.score(X_train_multi, y_train_multi)\n",
    "print(f'Predictive score on training data {train_score:.4f}')\n",
    "\n",
    "test_score = clf.score(X_test_multi, y_test_multi)\n",
    "print(f'Predictive score on test data {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33503645-4aa3-4b37-a05c-fec91afd78b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of decision tree 39.0000\n"
     ]
    }
   ],
   "source": [
    "depth = clf.get_depth()\n",
    "print(f'Depth of decision tree {depth:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfede50a-1995-42c3-83db-c82c0c7b66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure = plt.figure(figsize=(25,20))\n",
    "#tree_plt = tree.plot_tree(clf, max_depth=3, feature_names=X_train_multi.columns, class_names=\"cnt_bins\", filled=True, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c6231-32b3-403e-98ba-33f770e7128a",
   "metadata": {},
   "source": [
    "The test score is about the same as for the tuned version of K-nearest neighbors. However, we can see that the model perform very well on the train data and not so well for the test data. This is a sign of overfitting. To prevent overfitting of decision trees, we want to prune the tree, i.e. prevent it from growing to its full depth. We want to perform pre-pruning, which involves tuning the hyperparameters. The hyperparameters we are going to prune are max_depth, min_samples_leaf and min_samples_split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19f14b7-3764-4d91-bb4c-0816ee846eed",
   "metadata": {},
   "source": [
    "#### Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c20b163-99ce-4efb-bc42-7a14a3bef02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data after modifications 0.8007\n",
      "Predictive score on test data after modifications 0.6464\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "param_grid = {'max_depth':[5,10,15,20,25,20,35,39], 'min_samples_leaf':[1,2,3,4,5], 'min_samples_split':[2,4,6,8,10]}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, return_train_score=True).fit(X_train_multi, y_train_multi)\n",
    "\n",
    "train_score = grid_search.best_estimator_.fit(X_train_multi, y_train_multi).score(X_train_multi, y_train_multi)\n",
    "print(f'Predictive score on training data after modifications {train_score:.4f}')\n",
    "\n",
    "test_score = grid_search.best_estimator_.score(X_test_multi, y_test_multi)\n",
    "print(f'Predictive score on test data after modifications {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b110fbd7-fcaf-41ef-a5f6-986a0e0505a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_multi = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9710a1-976b-49d6-b6e0-8dffa3344fe3",
   "metadata": {},
   "source": [
    "The model is not overfitting as much anymore, but the test accuracy (64%) is not significantly better than the test accuracy for k-nearest neighbors (64%). Next step is to try two-class classification for decision trees to see if the accuracy is better than for k-nearest neighbors, logistic regression and the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a70bf955-660a-4a10-b54c-74c8224486d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data after modifications 0.9419\n",
      "Predictive score on test data after modifications 0.8843\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "param_grid = {'max_depth':[5,10,15,20,25,20,35,39], 'min_samples_leaf':[1,2,3,4,5], 'min_samples_split':[2,4,6,8,10]}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, return_train_score=True).fit(X_train_two, y_train_two)\n",
    "\n",
    "train_score = grid_search.best_estimator_.fit(X_train_two,y_train_two).score(X_train_two, y_train_two)\n",
    "print(f'Predictive score on training data after modifications {train_score:.4f}')\n",
    "\n",
    "test_score = grid_search.best_estimator_.score(X_test_two, y_test_two)\n",
    "print(f'Predictive score on test data after modifications {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "799478f9-d5af-4ae1-b9e2-8f64cb454c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_two = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbaec0b-d685-4ca5-81f5-000dcd57fac6",
   "metadata": {},
   "source": [
    "Similar to k-nearest neighbors, the accuracy for two-class decision tree classification (test: 88%) is significantly better than for multi-class decision tree classification (test: 65%). However, the accuracy is similar to the accuracy for k-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ccc4e-5b03-45ae-8360-bac360dba2d0",
   "metadata": {},
   "source": [
    "## Method 4: Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92039298-bf6c-450d-9872-b3f475f42f5d",
   "metadata": {},
   "source": [
    "We want to improve the accuracy of the decision trees by using the random forest classifier. The random forest classifier will combine the outputs from several decision trees to one result. Again, we start with multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44116634-d052-42a0-bcf0-0902acd6301a",
   "metadata": {},
   "source": [
    "#### Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37593842-d14d-44fa-bd3c-8dd6ff82822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data 0.8183\n",
      "Predictive score on test data 0.6533\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=seed).fit(X_train_multi, y_train_multi)\n",
    "\n",
    "train_score = grid_search.best_estimator_.fit(X_train_multi, y_train_multi).score(X_train_multi, y_train_multi)\n",
    "print(f'Predictive score on training data {train_score:.4f}')\n",
    "\n",
    "test_score = grid_search.best_estimator_.score(X_test_multi, y_test_multi)\n",
    "print(f'Predictive score on test data {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd469745-c494-4770-83da-ff633a0bdbab",
   "metadata": {},
   "source": [
    "The test score (65%) is significantly better than the score of the multi-class baseline model. However, the score is about the same as for the decison tree. To improve the accuracy of the random forest, we tune the n_estimator hyperparameter. For the other hyperparameters, we use the optimal parameters from the tuned decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1a8ee-b775-4124-942d-df2dd030d994",
   "metadata": {},
   "source": [
    "#### Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ef21ad6-fde2-4a9d-9f9a-68d35843f1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data after modifications 0.8428\n",
      "Predictive score on test data after modifications 0.6631\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=best_params_multi['max_depth'], min_samples_leaf=best_params_multi['min_samples_leaf'], min_samples_split=best_params_multi['min_samples_split'], random_state=seed)\n",
    "\n",
    "param_grid = {'n_estimators':[100,200,300,400,500,600,700,800,900,1000]}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, return_train_score=True).fit(X_train_multi, y_train_multi)\n",
    "\n",
    "train_score = grid_search.best_estimator_.fit(X_train_multi, y_train_multi).score(X_train_multi, y_train_multi)\n",
    "print(f'Predictive score on training data after modifications {train_score:.4f}')\n",
    "\n",
    "test_score = grid_search.best_estimator_.score(X_test_multi, y_test_multi)\n",
    "print(f'Predictive score on test data after modifications {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b6b4d84-7fe3-4d0d-ab4c-ef875f046cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of decision trees in the random forest 500.0000\n"
     ]
    }
   ],
   "source": [
    "optimal_n_estimators = grid_search.best_params_['n_estimators']\n",
    "\n",
    "print(f'Optimal number of decision trees in the random forest {optimal_n_estimators:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c94c0e8-bd3c-490d-809d-8a069bc9273b",
   "metadata": {},
   "source": [
    "The test score improved sligthly when we tuned the number of decision trees in the forest (67%). The cross validation shows that the optimal number of trees is 500.\n",
    "\n",
    "To end our discussion of random forests, we want to try two-class random forest classification to see if it performes better than the two-class baseline, logistic regression, k-nearest neighbors and decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "125d1d3e-e9eb-4cca-b09f-d71b8fcddbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive score on training data after modifications 0.9351\n",
      "Predictive score on test data after modifications 0.8993\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=best_params_two['max_depth'], min_samples_leaf=best_params_two['min_samples_leaf'], min_samples_split=best_params_two['min_samples_split'], random_state=seed)\n",
    "\n",
    "param_grid = {'n_estimators':[100,200,300,400,500,600,700,800,900,1000]}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, return_train_score=True).fit(X_train_two, y_train_two)\n",
    "\n",
    "train_score = grid_search.best_estimator_.fit(X_train_two,y_train_two).score(X_train_two, y_train_two)\n",
    "print(f'Predictive score on training data after modifications {train_score:.4f}')\n",
    "\n",
    "test_score = grid_search.best_estimator_.score(X_test_two, y_test_two)\n",
    "print(f'Predictive score on test data after modifications {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e123ee-2aec-4604-b601-4b77a18504c3",
   "metadata": {},
   "source": [
    "Similar to both k-nearest neighbors and decision trees, the score for two-class random forest classification is significantly better than the multi-class classification. The model performes equally good as k-nearest neighbors and decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbcdaa5-00b9-42db-a256-2901699cc6fc",
   "metadata": {},
   "source": [
    "## Conclution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48d365-d6ed-46ba-8f6d-beccf2b49587",
   "metadata": {},
   "source": [
    "The best score we got for multi-class classification was 0.66 with random forest. K-nearest neighbors, decision trees and random forest performed equally on two-clas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
