{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ea91bc-0223-4418-8f65-24f585897ba7",
   "metadata": {},
   "source": [
    "In this notebook, we will use regression algorithms to predict the number of rented bikes for a given day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8966fe6-2c9b-4ab5-aa61-5bdeb9bed533",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d2deadf-1aa1-49d4-a994-b09e2b922d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "seed=99\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd23f85c-89fc-4b91-9073-1d0bf2c9ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental = pd.read_csv('data/rental.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5ff02-e703-4e82-9c29-af5894a597a0",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c68efc-6ace-4279-a521-47bcf35b196c",
   "metadata": {},
   "source": [
    "Usually, standardization and normalization may be used on the independent variables as some machine learning algorithm is sensitive to the scale and distribution of the data such as SVM and linear regression. Scaling issues may result in features with larger values having more importance than others and ignore the features with lower values, impacting the model performance.\n",
    "\n",
    "From our EDA phase, we do not see any significant scaling issues, even though some of the features with numerical label encoding do have higher values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df0b9f-c1f7-465c-8937-86fa69254b80",
   "metadata": {},
   "source": [
    "# Predictive modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9a691c-b42f-42a7-bece-527dc740ec85",
   "metadata": {},
   "source": [
    "Standardization function is copied from PS4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e7fa2-07b1-47b3-a8be-caf73e1612a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def standardize(raw_data):\n",
    "    return ((raw_data - np.mean(raw_data, axis = 0)) / np.std(raw_data, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae7b2a34-6558-4ba1-be58-0e8a9b1d3851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>season_1</th>\n",
       "      <th>season_2</th>\n",
       "      <th>season_3</th>\n",
       "      <th>season_4</th>\n",
       "      <th>year_0</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>workingday_0</th>\n",
       "      <th>workingday_1</th>\n",
       "      <th>weathersit_1</th>\n",
       "      <th>weathersit_2</th>\n",
       "      <th>weathersit_3</th>\n",
       "      <th>weathersit_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  temp   atemp   hum  windspeed  season_1  season_2  season_3  \\\n",
       "0        1  0.24  0.2879  0.81        0.0       1.0       0.0       0.0   \n",
       "1        2  0.22  0.2727  0.80        0.0       1.0       0.0       0.0   \n",
       "2        3  0.22  0.2727  0.80        0.0       1.0       0.0       0.0   \n",
       "3        4  0.24  0.2879  0.75        0.0       1.0       0.0       0.0   \n",
       "4        5  0.24  0.2879  0.75        0.0       1.0       0.0       0.0   \n",
       "\n",
       "   season_4  year_0  ...  weekday_3  weekday_4  weekday_5  weekday_6  \\\n",
       "0       0.0     1.0  ...        0.0        0.0        0.0        1.0   \n",
       "1       0.0     1.0  ...        0.0        0.0        0.0        1.0   \n",
       "2       0.0     1.0  ...        0.0        0.0        0.0        1.0   \n",
       "3       0.0     1.0  ...        0.0        0.0        0.0        1.0   \n",
       "4       0.0     1.0  ...        0.0        0.0        0.0        1.0   \n",
       "\n",
       "   workingday_0  workingday_1  weathersit_1  weathersit_2  weathersit_3  \\\n",
       "0           1.0           0.0           1.0           0.0           0.0   \n",
       "1           1.0           0.0           1.0           0.0           0.0   \n",
       "2           1.0           0.0           1.0           0.0           0.0   \n",
       "3           1.0           0.0           1.0           0.0           0.0   \n",
       "4           1.0           0.0           1.0           0.0           0.0   \n",
       "\n",
       "   weathersit_4  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = rental.loc[:, rental.columns != 'cnt']\n",
    "y = rental['cnt']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd8cac-e3d8-4ed3-a81c-142e0457dbff",
   "metadata": {},
   "source": [
    "## Method 1: Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98151df9-6a45-4eda-aa0d-fe8401472edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "score = lin_reg.score(X_train, y_train)\n",
    "print(f'Predictive score on training data {score:.4f}')\n",
    "\n",
    "score = lin_reg.score(X_test, y_test)\n",
    "print(f'Predictive score on test data {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dca6d9-579e-4319-bf16-af54a1df73c9",
   "metadata": {},
   "source": [
    "The linear regression model provides us with a baseline which we can compare our other predictive algorithms on. This model got a score of 0.69 on the training data and 0.67 on the test set.\n",
    "\n",
    "The score metric returns the R-squared value which describes how much of the variance the model is able to explain. We will use this metric throughout the notebook to compare the models deciding which has the best goodness of fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807e9225-f177-4d46-8e30-883c28700102",
   "metadata": {},
   "source": [
    "## Method 2. Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a97bf-a54f-4ea1-8708-ad4a56e707eb",
   "metadata": {},
   "source": [
    "#### Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c19cc-edb4-4dd4-b017-7f893e5b8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbm = GradientBoostingRegressor(random_state=seed)\n",
    "\n",
    "# Fit the model and make prediction\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "cross_score = np.mean(cross_val_score(gbm, X_train, y_train, cv=10))\n",
    "train_score = gbm.score(X_train, y_train)\n",
    "test_score = gbm.score(X_test, y_test)\n",
    "\n",
    "\n",
    "print('Training set {:.4f}'.format(train_score))\n",
    "print('Cross-validated set: {:.4f}'.format(cross_score))\n",
    "print('Test set: {:.4f}'.format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc0153-25a7-4910-a70c-93c557ef409e",
   "metadata": {},
   "source": [
    "#### Finetuned model\n",
    "Use a grid search algorithm to find the best hyperparameters for the gradient boosting algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18eaec-6c10-421a-800d-5585c0962aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [2, 5, 6, 7, 9, 11],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'min_samples_leaf': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "gbm = GradientBoostingRegressor(random_state=seed)\n",
    "\n",
    "cv_search = GridSearchCV(gbm, param_grid, cv=5, verbose=True, n_jobs=-1).fit(X_train, y_train)\n",
    "print(\"best parameters:\", cv_search.best_params_)\n",
    "# best parameters: {'learning_rate': 0.1, 'max_depth': 11, 'min_samples_leaf': 7, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a86aa3-d35b-44d3-8fc9-e8db24833896",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set {:.4f}'.format(cv_search.best_estimator_.fit(X_train, y_train).score(X_train, y_train)))\n",
    "print('Cross-validated set: {:.4f}'.format(cv_search.best_score_))\n",
    "print('Test set: {:.4f}'.format(cv_search.best_estimator_.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee65b98-0b48-4501-a2e3-ef3a0b0386d6",
   "metadata": {},
   "source": [
    "The first model was trained using the default parameters of the gradient boosting algorithm and got a significant higher score than the multiple regression model with an increase from 0.68 to 0.79.\n",
    "\n",
    "Due to the performance of the gradient boosting algorithm, we decided to finetune the hyperparameters to see if we could get a better performance. After using grid search to test out combinations of different parameters we got a satisfying result of 0.9840 on the training set, 0.9368 on cross-validation, and 0.9422 on the test set with the following parameters:  \n",
    "* best parameters: {'learning_rate': 0.1, 'max_depth': 11, 'min_samples_leaf': 9, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a642a05-34c3-4335-bdec-873d8d34824c",
   "metadata": {},
   "source": [
    "## Method 3. Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16285bd8-6136-432f-88f7-bd2e63c2ed68",
   "metadata": {},
   "source": [
    "#### Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2035ec10-8bd5-4170-a205-cb40a9217cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=seed)\n",
    "\n",
    "# Fit the model and make prediction\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "cross_score = np.mean(cross_val_score(dtr, X_train, y_train, cv=10))\n",
    "train_score = dtr.score(X_train, y_train)\n",
    "test_score = dtr.score(X_test, y_test)\n",
    "\n",
    "print('Training set {:.4f}'.format(train_score)) \n",
    "print('Cross-validated score: {:.4f}'.format(cross_score.mean()))\n",
    "print('Test set {:.4f}'.format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80955b-697f-45ba-82d1-30c0ca375baa",
   "metadata": {},
   "source": [
    "The decision tree model with default parameters got a better score than the default gradient boosting alternative, but performed worse than the fine-tuned gradient boosting model. The performance on the training set is also significant better than on the test set. This difference may indicate an overfit on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297469a1-fd79-4bf4-a838-ab963bc274b9",
   "metadata": {},
   "source": [
    "#### Fine-tuning of the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa7a3e5-b2fd-4ffb-a5f6-d31dc50c27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [2, 5, 6, 7, 9, 11],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'min_samples_leaf': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=seed)\n",
    "\n",
    "cv_search = GridSearchCV(dt, param_grid, cv=5, verbose=True, n_jobs=-1).fit(X_train, y_train)\n",
    "print(\"best parameters:\", cv_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c962a0e-d21a-4e05-ac50-8adac6b5cddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set {:.4f}'.format(cv_search.best_estimator_.fit(X_train, y_train).score(X_train, y_train)))\n",
    "print('Cross-validated score: {:.4f}'.format(cv_search.best_score_))\n",
    "print('Test set: {:.4f}'.format(cv_search.best_estimator_.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e667b1-e9d7-4402-9bcf-b5f2fb9b4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the decision tree\n",
    "fig = plt.figure(figsize=(32,15))\n",
    "plot_tree(dtr, fontsize=15, max_depth=3, feature_names=X_train.columns, class_names=['Not survived', 'Survived'], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624aac5-af14-4dee-bd53-018abc454032",
   "metadata": {},
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8129b5c-fa70-40d9-980c-3bb5367bac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.barplot(x=dtr.feature_importances_, y=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79154d4c-69cc-4e00-b4f9-971065b3bea0",
   "metadata": {},
   "source": [
    "## Method 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a95455-00d7-498a-aa98-6af13db3f80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 0.9901\n",
      "Cross-validated score: 0.9261\n",
      "Test set: 0.9335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fit the model and make prediction\n",
    "rf = RandomForestRegressor(random_state=seed) # Default parameters\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "cross_score = np.mean(cross_val_score(rf, X_train, y_train, cv=10))\n",
    "train_score = rf.score(X_train, y_train)\n",
    "test_score = rf.score(X_test, y_test)\n",
    "\n",
    "print('Training set {:.4f}'.format(train_score))\n",
    "print('Cross-validated score: {:.4f}'.format(cross_score))\n",
    "print('Test set: {:.4f}'.format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cfaee5-c9f8-4a6e-993f-cc512c02dd32",
   "metadata": {},
   "source": [
    "From the default models we earlier have fitted, this gives the best goodness of fit. Therefore, I will fine-tune the parameters in order to see if we can improve the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d89268-d47a-437d-9790-cfe636202213",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db72829-46f6-4c00-9f8c-40b77d996a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n",
      "best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "\n",
    "cv_search = GridSearchCV(rf, param_grid, cv=5, verbose=True, n_jobs=-1).fit(X_train, y_train)\n",
    "print(\"best parameters:\", cv_search.best_params_)\n",
    "#best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fdd1ba7-ac06-494b-a99d-9dd7801c9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set 0.9901\n",
      "Cross-validated score: 0.9219\n",
      "Test set: 0.9335\n"
     ]
    }
   ],
   "source": [
    "print('Training set {:.4f}'.format(cv_search.best_estimator_.fit(X_train, y_train).score(X_train, y_train)))\n",
    "print('Cross-validated score: {:.4f}'.format(cv_search.best_score_))\n",
    "print('Test set: {:.4f}'.format(cv_search.best_estimator_.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55ecab5f-99dc-4a82-b4c3-aaa749fab455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933511308196414"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestRegressor(random_state=seed, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "rf2.fit(X_train, y_train)\n",
    "rf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996063c-d03d-4032-a5b0-e0dda48e9634",
   "metadata": {},
   "source": [
    "The fine-tuned random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f44b1b-b319-4521-8561-b5b28f74a121",
   "metadata": {},
   "source": [
    "## Method 7. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3896c-704c-4308-9641-c443535ec8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Fine-tune\n",
    "svr = SVR()\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'epsilon': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "#grid_search = GridSearchCV(svr, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "#grid_search.fit(X_train, y_train)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "cross_score = np.mean(cross_val_score(svr, X_train, y_train, cv=10))\n",
    "train_score = svr.score(X_train, y_train)\n",
    "test_score = svr.score(X_test, y_test)\n",
    "\n",
    "print('Training set {:.4f}'.format(train_score))\n",
    "print('Cross-validated score: {:.4f}'.format(cross_score))\n",
    "print('Test set: {:.4f}'.format(test_score))\n",
    "\n",
    "# Took too long time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59f9a6-dd85-4017-8b57-5e6a257b4c92",
   "metadata": {},
   "source": [
    "## Method 8. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b942c8e-f643-4f25-8115-5111bd1c9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1])))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
